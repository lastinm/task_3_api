# task_3_api (вторая версия)

# Об использованной модели машинного обучения

В качестве модели распознавания использована следующая модель:
https://huggingface.co/cointegrated/rubert-tiny-toxicity

Это коинтегрированная модель Руберта-Тайни, 
доработанная для классификации токсичности и неуместности коротких неформальных русских текстов, 
таких как комментарии в социальных сетях.

Достоинство данной модели - это ее очень малый размер, всего 47,2 Мб.
model.safetensors: 100%|██████████| 47.2M

При таком невероятно малом размере, модель сохраняет возможность находить токсичность в переданных текстах.

# Работа приложения

Для распознавания укажем такой текст (прощу прощения за грубость, но нужно проверять работу):
"Эта лодка дырявая калоша".

Получаем ответ (вероятность того, что текст содержит токсичные выражения): 0.978443726230604.
Как видим, модель отработала верно. С вероятностью 0.998 было определено, что текст токсичен.

Теперь введем: "Ты мой ласковый и нежный зверь".
Получаем ответ:  0.024751935718452467.
Модель снова отработала успешно, определив вероятность 0,024 того, что текст является токсичным.

# Проверка работы API

Для проверки разработаны скриты для утилиты curl:
1. curl_get_local_root.sh - проверяем обращение методом GET к корню сайта;
2. curl_post_local_predict.sh - проверяем обращения методом POST по пути /predict/.

# task_3_api (первая версия)
Практическая работа №3. Ичучаем библиотеку FastAPI для создания API веб-приложения на Python.

Используем обученную модель "xlm-roberta-base" по подбору подходящих определений вместо шаблона.

Отпраляем POST запрос в формате JSON на адрес http://<НАШ АДРЕС>/predict/:

{	"text": "Этот <mask> стол здесь не стоял."}

Модель подбирает подходящие слова вместо шаблона и выдает примерно такой результат:

    {
        "score": 0.28582847118377686,
        "token": 1355,
        "token_str": "же",
        "sequence": "Этот же стол здесь не стоял."
    },
    {
        "score": 0.09806855767965317,
        "token": 182576,
        "token_str": "маленький",
        "sequence": "Этот маленький стол здесь не стоял."
    },
    {
        "score": 0.09025130420923233,
        "token": 227912,
        "token_str": "огромный",
        "sequence": "Этот огромный стол здесь не стоял."
    },
    {
        "score": 0.08879922330379486,
        "token": 55270,
        "token_str": "большой",
        "sequence": "Этот большой стол здесь не стоял."
    },
    {
        "score": 0.07688627392053604,
        "token": 62936,
        "token_str": "самый",
        "sequence": "Этот самый стол здесь не стоял."
    }





